# ğŸ› ï¸ Atividade PrÃ¡tica: OrquestraÃ§Ã£o de Pipelines com Dados JSON

## ğŸ§  Objetivo

O objetivo desta atividade Ã© praticar o uso de uma ferramenta de orquestraÃ§Ã£o (como Apache Airflow, Prefect, Mage ou outras) para construir um pipeline simples com trÃªs etapas principais:

1. **IngestÃ£o** dos dados a partir de dois arquivos JSON;
2. **TransformaÃ§Ã£o** dos dados em uma Ãºnica estrutura consolidada;
3. **GeraÃ§Ã£o** de uma tabela final cruzando as informaÃ§Ãµes dos dois arquivos.

---

## ğŸ“ Estrutura de Dados

O repositÃ³rio contÃ©m os seguintes arquivos de entrada, localizados na pasta `data/raw/`:

- `listing_scrape.json`: contÃ©m os dados principais dos anÃºncios.
- `listing_availability_scrape.json`: contÃ©m informaÃ§Ãµes de disponibilidade dos anÃºncios.

---

## ğŸ” Etapas do Pipeline

### 1. IngestÃ£o
- Carregar os dois arquivos JSON brutos a partir do diretÃ³rio `data/raw/`.

### 2. TransformaÃ§Ã£o
- Realizar um **join** (cruzamento) entre os dois conjuntos de dados.
- A chave principal Ã© o campo `listing_id`.

### 3. GeraÃ§Ã£o da Tabela Final
- Salvar os dados transformados em um novo arquivo no diretÃ³rio `data/processed/` com o nome `final_table.parquet` (ou `.csv`, se preferir).

---

## ğŸ§ª Requisitos da Atividade

- Use uma ferramenta de orquestraÃ§Ã£o de sua escolha para controlar as etapas do pipeline;
- O pipeline deve ser reexecutÃ¡vel (idempotente);
- Utilize boas prÃ¡ticas de modularizaÃ§Ã£o e logging;
- O pipeline deve prever possÃ­veis falhas (ex: arquivos ausentes, campos nulos, schemas incompatÃ­veis);
- Ao final, o pipeline deve gerar logs indicando o sucesso ou falha de cada etapa.

---

## ğŸš€ SugestÃ£o de Ferramentas

- [Apache Airflow](https://airflow.apache.org/)
- [Prefect](https://www.prefect.io/)
- [Mage](https://www.mage.ai/)
- [Dagster](https://dagster.io/)
- Ou scripts Python com agendamento via cron como alternativa simplificada

---

## ğŸ“¦ Estrutura Esperada do Projeto

atividade_orquestracao/
â”œâ”€â”€ dags/ # CÃ³digo do pipeline (caso use Airflow)
â”œâ”€â”€ flows/ # CÃ³digo do pipeline (caso use Prefect, Mage, etc.)
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ raw/
â”‚ â”‚ â”œâ”€â”€ listing_scrape.json
â”‚ â”‚ â””â”€â”€ listing_availability_scrape.json
â”‚ â””â”€â”€ processed/
â”‚ â”‚ â”œâ”€â”€ final_table.parquet
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
---

## âœ… Entrega Esperada

- Um repositÃ³rio com o pipeline funcionando e instruÃ§Ãµes de execuÃ§Ã£o no `README.md`;
- O script ou DAG deve ser facilmente executÃ¡vel;
- Inclua prints ou outputs mostrando o sucesso da execuÃ§Ã£o e o arquivo final gerado.

---

## ğŸ“š ReferÃªncias e InspiraÃ§Ã£o

- Pipelines ELT com Airflow: [Link]
- Prefect Flows com arquivos locais: [Link]
- TransformaÃ§Ãµes com pandas e joins em JSON: [Link]

---

---

## ğŸ”„ Como ComeÃ§ar: Fork e ConfiguraÃ§Ã£o Local

1. **Fork este repositÃ³rio** para sua conta GitHub:
   - Clique no botÃ£o **Fork** no canto superior direito da pÃ¡gina.
   - Escolha sua conta pessoal ou organizacional como destino.

2. **Clone o repositÃ³rio forkado** para sua mÃ¡quina local:

   ```bash
   git clone https://github.com/<usuario>/atividade_orquestracao.git
   ```

